{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AsZ4bJQoGVW"
      },
      "source": [
        "# Data Cleaning (preparation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZfC-Zq49CgD",
        "outputId": "cb25bf58-41f4-4821-939c-60a539bdabb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2025.9.3-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading rdkit-2025.9.3-cp312-cp312-manylinux_2_28_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2025.9.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umdDHJMSzCO1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('DAT.csv', sep=';')\n",
        "\n",
        "# Remove those units are not 'nM'\n",
        "df_new = df[df['Standard Units'] == 'nM'].copy()\n",
        "\n",
        "# Ensure the values are numeric\n",
        "df_new['Standard Value'] = pd.to_numeric(df['Standard Value'], errors = 'coerce')\n",
        "df_new = df.dropna(subset=['Standard Value','Smiles'])\n",
        "\n",
        "print(f\"有效數據量:{len(df_new)} 筆\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-iS-JOtz0VO"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem.SaltRemover import SaltRemover\n",
        "\n",
        "def clean_salts(smiles_list):\n",
        "  # Initialise SaltRemover\n",
        "  remover = SaltRemover()\n",
        "  cleaned_smiles = []\n",
        "\n",
        "  for smi in smiles_list:\n",
        "    try:\n",
        "      mol = Chem.MolFromSmiles(smi)\n",
        "      if mol:\n",
        "        # 移除鹽類\n",
        "        res = remover.StripMol(mol)\n",
        "        # 轉回SMILES字串\n",
        "        cleaned_smiles.append(Chem.MolToSmiles(res))\n",
        "\n",
        "      else:\n",
        "        cleaned_smiles.append(None)\n",
        "\n",
        "    except:\n",
        "      cleaned_smiles.append(None)\n",
        "\n",
        "  return cleaned_smiles\n",
        "\n",
        "df_new['Smiles'] = clean_salts(df_new['Smiles'])\n",
        "df_new = df_new.dropna(subset=['Smiles'])\n",
        "\n",
        "print(len(df_new))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_vLdrmABSpu"
      },
      "outputs": [],
      "source": [
        "# Check if the 'Smiles' is multiple\n",
        "df_new_unique = df_new.groupby('Smiles').agg({\n",
        "    'Standard Value':'median', #活性取中位數\n",
        "    'Molecule ChEMBL ID':'first' #ID取第一個代表\n",
        "}).reset_index()\n",
        "\n",
        "print(f\"去重複後數據量:{len(df_new_unique)}筆\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dq1xnU_HWgnK"
      },
      "outputs": [],
      "source": [
        "# Generate the label of active/inactive [Classification]\n",
        "threshold = 1000\n",
        "df_new_unique['Label'] = (df_new_unique['Standard Value'] <= threshold).astype(int)\n",
        "df_new_unique.to_csv('DAT_Cleaned_Labeled.csv', index=False)\n",
        "\n",
        "# Final Results\n",
        "print('\\n標籤分布情況')\n",
        "print(df_new_unique['Label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcIzQ_OBY8Yd"
      },
      "outputs": [],
      "source": [
        "# Sanity Check: Methylphenidate\n",
        "\n",
        "target_id = 'CHEMBL796'\n",
        "\n",
        "drug_row = df_new_unique[df_new_unique['Molecule ChEMBL ID'] == target_id]\n",
        "\n",
        "if not drug_row.empty:\n",
        "  print(\"✅ 找到 Methylphenidate 了！詳細數據如下：\")\n",
        "  print(\"-\" * 50)\n",
        "  print(f\"ChEMBL ID:      {drug_row['Molecule ChEMBL ID'].values[0]}\")\n",
        "  print(f\"SMILES 結構:    {drug_row['Smiles'].values[0]}\")\n",
        "  print(f\"IC50 (nM):      {drug_row['Standard Value'].values[0]}\")\n",
        "  print(f\"標籤 (Label):   {drug_row['Label'].values[0]}\")\n",
        "  print(\"-\" * 50)\n",
        "\n",
        "  ic50 = drug_row['Standard Value'].values[0]\n",
        "  label = drug_row['Label'].values[0]\n",
        "\n",
        "  if label == 1 and ic50 < 1000:\n",
        "    print(\"Conclusion: the data is reasonable. Drug is correctly labelled as active.\")\n",
        "\n",
        "  else:\n",
        "    print(\"Warning! Weird\")\n",
        "\n",
        "else:\n",
        "  print(\"Warning! No CHEMBL 796 in this dataset!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TxzXix5oB3u"
      },
      "source": [
        "# Feature Engineering - FingerPrint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GbRmrWXhDl0"
      },
      "outputs": [],
      "source": [
        "from rdkit.Chem import AllChem\n",
        "import numpy as np\n",
        "from rdkit.Chem import rdFingerprintGenerator\n",
        "\n",
        "df = pd.read_csv('DAT_Cleaned_Labeled.csv')\n",
        "\n",
        "# fpSize = 2048 (Fingerprint length)\n",
        "mfpgen = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=2048)\n",
        "\n",
        "def smiles_to_fp(smiles, radius=2, n_bits = 2048):\n",
        "    \"\"\"\n",
        "    將SMILES轉換為Morgan Fingerprint(位元陣列)\n",
        "    radius = 2 相當於ECFP4\n",
        "    [4 in ECFP4 corresponds to the diameter of the atom environments considered,\n",
        "    while the Morgan fingerprints take a radius parameter.\n",
        "    So the examples above, with radius=2, are roughly equivalent to ECFP4 and FCFP4.]\n",
        "    from rdkit.org/\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "      mol = Chem.MolFromSmiles(smiles)\n",
        "      if mol:\n",
        "        # 生成指紋物件\n",
        "        fp = mfpgen.GetFingerprint(mol)\n",
        "        # 轉換為Numpy陣列\n",
        "        arr = np.zeros((1,))\n",
        "        Chem.DataStructs.ConvertToNumpyArray(fp, arr)\n",
        "        return arr\n",
        "\n",
        "      else:\n",
        "       return None\n",
        "\n",
        "    except:\n",
        "      return None\n",
        "\n",
        "print(\"正在生成 Morgan Fingerprints (2048 bit)...\")\n",
        "\n",
        "# 執行轉換\n",
        "fps = [smiles_to_fp(s) for s in df['Smiles']]\n",
        "\n",
        "# 每一行是一個分子、每一列是一個特徵(Bit)\n",
        "X = np.array(fps)\n",
        "y = df['Label'].values\n",
        "\n",
        "print(f\"特徵矩陣形狀X shape: {X.shape}\")\n",
        "print(f\"標籤形狀y shape: {y.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-6IHNFZC0jik",
        "outputId": "90c0514a-8cc9-49e4-c0d9-6d92b11e79db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGOloXhNwmxZ"
      },
      "source": [
        "# Feature Engineering - Graph Data for the future GNN use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hDK6cH1qqv3I"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "\n",
        "# 1. 原子特徵提取函數\n",
        "def get_atom_features(atom):\n",
        "\n",
        "  # Extract 原子序數,雜化軌域, 是否在環上\n",
        "  features = [\n",
        "      atom.GetAtomicNum(),\n",
        "      atom.GetChiralTag(),\n",
        "      atom.GetTotalDegree(),\n",
        "      atom.GetFormalCharge(),\n",
        "      atom.GetTotalNumHs(),\n",
        "      atom.GetIsAromatic(),\n",
        "      atom.GetHybridization()\n",
        "  ]\n",
        "\n",
        "  return np.array(features, dtype = np.float32)\n",
        "\n",
        "# 2. SMILES --> Graph\n",
        "def smiles_to_graph(smiles, label):\n",
        "  mol = Chem.MolFromSmiles(smiles)\n",
        "  if not mol:\n",
        "    return None\n",
        "\n",
        "  # 節點特徵(Node Features)\n",
        "  atom_features = []\n",
        "  for atom in mol.GetAtoms():\n",
        "    atom_features.append(get_atom_features(atom))\n",
        "\n",
        "  x = torch.tensor(atom_features, dtype = torch.float)\n",
        "\n",
        "  # 邊緣特徵(Edge Features / Adjacency)\n",
        "  edge_indices = []\n",
        "  for bond in mol.GetBonds():\n",
        "    i = bond.GetBeginAtomIdx()\n",
        "    j = bond.GetEndAtomIdx()\n",
        "    # 無向圖: 需要雙向連接\n",
        "    edge_indices += [[i, j], [j,i]]\n",
        "\n",
        "  # 如果分子只有一個原子(沒有鍵)，處理edge_index\n",
        "  if len(edge_indices)>0:\n",
        "    edge_index = torch.tensor(edge_indices, dtype = torch.long).t().contiguous()\n",
        "\n",
        "  else:\n",
        "    edge_index = torch.empty((2,0), dtype = torch.long)\n",
        "\n",
        "  # 標籤(y)\n",
        "  y = torch.tensor([label], dtype = torch.long)\n",
        "\n",
        "  # 封裝成PyG Data 物件\n",
        "  return Data(x = x, edge_index = edge_index, y = y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CAtQion2wwHE",
        "outputId": "ffbf1416-508c-4e1a-edae-d1b0d185492f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "正在將SMILES轉換為分子圖數據\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2841401233.py:31: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  x = torch.tensor(atom_features, dtype = torch.float)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 成功轉換2361 個分子圖\n",
            "\n",
            "Batch範例\n",
            "DataBatch(x=[745, 7], edge_index=[2, 1632], y=[32], batch=[745], ptr=[33])\n",
            "該Batch分子總原子數: 745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1942535130.py:15: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  loader = DataLoader(data_list, batch_size=32, shuffle = True)\n"
          ]
        }
      ],
      "source": [
        "# 3. Read Data and Convert\n",
        "df = pd.read_csv('DAT_Cleaned_Labeled.csv')\n",
        "data_list = []\n",
        "\n",
        "print(\"正在將SMILES轉換為分子圖數據\")\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "  graph = smiles_to_graph(row['Smiles'], row['Label'])\n",
        "  if graph:\n",
        "    data_list.append(graph)\n",
        "\n",
        "print(f\"✅ 成功轉換{len(data_list)} 個分子圖\")\n",
        "\n",
        "# 4.準備DataLoader (供GNN)\n",
        "loader = DataLoader(data_list, batch_size=32, shuffle = True)\n",
        "\n",
        "# Test: 查看第一個Batch\n",
        "for batch in loader:\n",
        "  print(\"\\nBatch範例\")\n",
        "  print(batch)\n",
        "  print(f\"該Batch分子總原子數: {batch.num_nodes}\")\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGVSYFPX6Qb6"
      },
      "source": [
        "#Training Phase: RF/XGBoost/GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zWOExwPz6Vjd",
        "outputId": "bf6fa189-2d65-48dd-cff3-a376118f82ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1068801127.py:11: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  train_loader = DataLoader(train_data, batch_size = 32, shuffle =True)\n",
            "/tmp/ipython-input-1068801127.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  test_loader = DataLoader(test_data, batch_size =32, shuffle = False)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# For Fingerprints(RF/XGBoost)\n",
        "# X: 2048-bit array, y:Label\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state=42)\n",
        "\n",
        "# For GNN (graphs)\n",
        "# data_list is the input data\n",
        "train_data, test_data = train_test_split(data_list, test_size = 0.2, random_state =42)\n",
        "train_loader = DataLoader(train_data, batch_size = 32, shuffle =True)\n",
        "test_loader = DataLoader(test_data, batch_size =32, shuffle = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-R8GAU-y8g-q"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "  def __init__(self, num_node_features):\n",
        "    super(GCN, self).__init__()\n",
        "    self.conv1 = GCNConv(num_node_features, 64)\n",
        "    self.conv2 = GCNConv(64,64)\n",
        "    self.fc = torch.nn.Linear(64,2)\n",
        "    # 分2類(0,1)\n",
        "\n",
        "  def forward(self,data):\n",
        "    x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "    # 1. 圖卷積層\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2(x, edge_index)\n",
        "\n",
        "    # 2. Pooling (把所有原子特徵都壓縮成一個分子的特徵)\n",
        "    x = global_mean_pool(x, batch)\n",
        "\n",
        "    # 3. 全連接層輸出\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "# 初始化GNN\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN(num_node_features =7).to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7ofTrWQEWJp"
      },
      "source": [
        "#Training Phase: Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h54g052CEQuV",
        "outputId": "3dc4b198-4e83-4e67-d41f-05cdbbb33dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Random Forest...\n",
            "Training XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [02:53:48] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Random Forest 效能報告 =====\n",
            "AUC-ROC Score: 0.9178\n",
            "F1 Score:      0.8495\n",
            "\n",
            "詳細分類指標:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81       210\n",
            "           1       0.85      0.85      0.85       263\n",
            "\n",
            "    accuracy                           0.83       473\n",
            "   macro avg       0.83      0.83      0.83       473\n",
            "weighted avg       0.83      0.83      0.83       473\n",
            "\n",
            "\n",
            "===== XGBoost 效能報告 =====\n",
            "AUC-ROC Score: 0.9178\n",
            "F1 Score:      0.8637\n",
            "\n",
            "詳細分類指標:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83       210\n",
            "           1       0.87      0.86      0.86       263\n",
            "\n",
            "    accuracy                           0.85       473\n",
            "   macro avg       0.85      0.85      0.85       473\n",
            "weighted avg       0.85      0.85      0.85       473\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from matplotlib import use\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,roc_auc_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Initiate the model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "# 2. Train the model\n",
        "print(\"Training Random Forest...\")\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training XGBoost...\")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Predict the result (probabilities and category)\n",
        "rf_probs = rf_model.predict_proba(X_test)[:,1]\n",
        "xgb_probs = xgb_model.predict_proba(X_test)[:,1]\n",
        "\n",
        "rf_preds = rf_model.predict(X_test)\n",
        "xgb_preds = xgb_model.predict(X_test)\n",
        "\n",
        "# 4. 效能報告\n",
        "def print_performance(name, y_true, y_pred, y_prob):\n",
        "    print(f\"\\n===== {name} 效能報告 =====\")\n",
        "    print(f\"AUC-ROC Score: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(f\"F1 Score:      {f1_score(y_true, y_pred):.4f}\")\n",
        "    print(\"\\n詳細分類指標:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "print_performance(\"Random Forest\", y_test, rf_preds, rf_probs)\n",
        "print_performance(\"XGBoost\", y_test, xgb_preds, xgb_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VtqLOEnIFbxj",
        "outputId": "ae826eb0-b647-460b-aec8-e30ded4d1bbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "指紋生成Success\n",
            "指紋形狀(Shape):(2048,)\n",
            "亮起的Bits 數量:36\n",
            "前 10 個亮起的 Bit 索引: [  1  54 147 185 305 325 389 604 650 695]\n"
          ]
        }
      ],
      "source": [
        "# 生成MPH的Fingerprint\n",
        "from rdkit.Chem import rdFingerprintGenerator\n",
        "\n",
        "mp_smiles = \"COC(=O)C(c1ccccc1)C1CCCCN1\"\n",
        "\n",
        "# 建立指紋生成器\n",
        "mfpgen = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=2048)\n",
        "\n",
        "# 轉換為分子物件\n",
        "mol = Chem.MolFromSmiles(mp_smiles)\n",
        "\n",
        "if mol:\n",
        "  # 生成指紋物件\n",
        "  fp = mfpgen.GetFingerprint(mol)\n",
        "\n",
        "  mp_fp_array = np.zeros((1,), dtype = int)\n",
        "  Chem.DataStructs.ConvertToNumpyArray(fp,mp_fp_array)\n",
        "\n",
        "  print(\"指紋生成Success\")\n",
        "  print(f\"指紋形狀(Shape):{mp_fp_array.shape}\")\n",
        "\n",
        "  # 看看哪些Bit是1(Active) - np.where 會回傳陣列中數值為1的index\n",
        "  on_bits = np.where(mp_fp_array ==1)[0]\n",
        "  print(f\"亮起的Bits 數量:{len(on_bits)}\")\n",
        "  print(f\"前 10 個亮起的 Bit 索引: {on_bits[:10]}\")\n",
        "\n",
        "  # 準備丟入模型預測 (Reshape 成 2D 矩陣)\n",
        "  # 模型通常預期輸入形狀為 (樣本數, 特徵數)，所以要變成 (1, 2048)\n",
        "  mp_input = mp_fp_array.reshape(1,-1)\n",
        "\n",
        "else:\n",
        "  print(\"❌ SMILES 解析失敗\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4a8D9bLn8sX-",
        "outputId": "865bf162-c9ef-422d-95c2-4cd9fca60401"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RF模型預測利他能對DAT有效的機率: 0.6167\n",
            "RF模型預測為有效\n",
            "XGB模型預測利他能對DAT有效的機率: 0.6489\n",
            "XGB模型預測為有效\n"
          ]
        }
      ],
      "source": [
        "# 丟進RF和XGB做預測\n",
        "\n",
        "probability_rf = rf_model.predict_proba(mp_input)[0][1]\n",
        "print(f\"RF模型預測利他能對DAT有效的機率: {probability_rf:.4f}\")\n",
        "\n",
        "if probability_rf > 0.5:\n",
        "  print(\"RF模型預測為有效\")\n",
        "else:\n",
        "  print(\"RF模型預測為無效\")\n",
        "\n",
        "probability_xg = xgb_model.predict_proba(mp_input)[0][1]\n",
        "print(f\"XGB模型預測利他能對DAT有效的機率: {probability_xg:.4f}\")\n",
        "\n",
        "if probability_xg > 0.5:\n",
        "  print(\"XGB模型預測為有效\")\n",
        "else:\n",
        "  print(\"XGB模型預測為無效\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-Sdclb1QDBdh",
        "outputId": "d196f638-8c30-4d19-d909-49cb3d65211f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "使用裝置:cpu\n",
            "\n",
            "開始訓練ＧＮＮ\n",
            "Epoch: 005, Loss: 0.6799, Train AUC: 0.6069, Test AUC: 0.6279\n",
            "Epoch: 010, Loss: 0.6704, Train AUC: 0.6343, Test AUC: 0.6678\n",
            "Epoch: 015, Loss: 0.6624, Train AUC: 0.6604, Test AUC: 0.7046\n",
            "Epoch: 020, Loss: 0.6550, Train AUC: 0.6780, Test AUC: 0.7234\n",
            "Epoch: 025, Loss: 0.6375, Train AUC: 0.7030, Test AUC: 0.7491\n",
            "Epoch: 030, Loss: 0.6290, Train AUC: 0.7270, Test AUC: 0.7667\n",
            "Epoch: 035, Loss: 0.6155, Train AUC: 0.7423, Test AUC: 0.7799\n",
            "Epoch: 040, Loss: 0.6097, Train AUC: 0.7531, Test AUC: 0.7833\n",
            "Epoch: 045, Loss: 0.5868, Train AUC: 0.7610, Test AUC: 0.7873\n",
            "Epoch: 050, Loss: 0.5865, Train AUC: 0.7666, Test AUC: 0.7895\n",
            "\n",
            "訓練完成\n"
          ]
        }
      ],
      "source": [
        "# 1. 設定訓練參數\n",
        "# =======================\n",
        "# 若有GPU則用GPU; 否則用CPU\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"使用裝置:{device}\")\n",
        "\n",
        "# 初始化模型：num_node_features = 7\n",
        "model = GCN(num_node_features = 7).to(device)\n",
        "\n",
        "# 定義優化器(Optimiser) -使用Adam: 動量和RMSProp的優化器;機器學習中用於調整模型參數以最小化損失函數\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay = 5e-4)\n",
        "\n",
        "# 定義Loss Function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# 2. 定義訓練函數\n",
        "# ======================\n",
        "def train():\n",
        "  # 訓練mode\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  for batch in train_loader:\n",
        "    batch = batch.to(device)\n",
        "\n",
        "    # 清空梯度\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward Pass\n",
        "    out = model(batch)\n",
        "\n",
        "    # 計算Loss\n",
        "    loss = criterion(out, batch.y)\n",
        "\n",
        "    # Backward Pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  return total_loss / len(train_loader)\n",
        "\n",
        "# 3. 定義測試/評估函數\n",
        "# ======================\n",
        "\n",
        "def test(loader):\n",
        "  # 評估模式\n",
        "  model.eval()\n",
        "\n",
        "  y_true = []\n",
        "  y_probs = []\n",
        "  y_preds = []\n",
        "\n",
        "  # 不計算梯度，節省記憶體\n",
        "  with torch.no_grad():\n",
        "    for batch in loader:\n",
        "      batch = batch.to(device)\n",
        "      out = model(batch)\n",
        "\n",
        "      # 取得預測機率(Softmax)\n",
        "      prob = F.softmax(out, dim=1)\n",
        "\n",
        "      # 收集結果\n",
        "      y_true.extend(batch.y.cpu().numpy())\n",
        "      # 取Class 1 (Active)的機率\n",
        "      y_probs.extend(prob[:,1].cpu().numpy())\n",
        "      # 取機率最大的類別\n",
        "      y_preds.extend(out.argmax(dim=1).cpu().numpy())\n",
        "\n",
        "  # 計算指標\n",
        "  auc = roc_auc_score(y_true, y_probs)\n",
        "  f1 = f1_score(y_true, y_preds)\n",
        "  return auc, f1\n",
        "\n",
        "# 4. 開始訓練迴圈\n",
        "# ======================\n",
        "print(\"\\n開始訓練ＧＮＮ\")\n",
        "# 訓練輪數\n",
        "epochs = 50\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "  train_loss = train()\n",
        "\n",
        "  # 每五個epoch檢查一次training set's efficacy\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    train_auc, train_f1 = test(train_loader)\n",
        "    test_auc, test_f1 = test(test_loader)\n",
        "\n",
        "    print(\"Epoch: {:03d}, Loss: {:.4f}, Train AUC: {:.4f}, Test AUC: {:.4f}\".format(\n",
        "    epoch, train_loss, train_auc, test_auc))\n",
        "\n",
        "print(\"\\n訓練完成\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WzXJCxCZCyv9",
        "outputId": "1cf6b7b3-2d18-4e90-cbd3-e3a790cba1b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=======GNN最終效能\n",
            "Test AUC-ROC: 0.7895\n",
            "Test F1 Score: 0.7765\n",
            "What an amazing progress! GNN's performance is better than the baseline so far\n"
          ]
        }
      ],
      "source": [
        "# 最終效能評估\n",
        "final_auc, final_f1 = test(test_loader)\n",
        "print(f\"\\n=======GNN最終效能\")\n",
        "print(f\"Test AUC-ROC: {final_auc:.4f}\")\n",
        "print(f\"Test F1 Score: {final_f1:.4f}\")\n",
        "\n",
        "# If Results for GNN >0.7 --> 分子圖結構特徵確實捕捉到Fingerprints漏掉的資訊\n",
        "if final_auc > 0.65:\n",
        "  print(\"What an amazing progress! GNN's performance is better than the baseline so far\")\n",
        "else:\n",
        "  print(\"GNN's performance is same or worse.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhxBAOZ_fXz9"
      },
      "source": [
        "#模型穩定性檢查 K-Fold Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EpIqPkQ7fW8h"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "def check_model_stability(model, X, y, n_splits=5):\n",
        "  # 使用Stratified K-Fold to check model stability\n",
        "\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    model: 定義好的模型物件(Random Forest/XGBoost)\n",
        "\n",
        "    X: 特徵矩陣(Features)\n",
        "    y: 標籤向量(Labels)\n",
        "    n_splits: 折數(預設5)\n",
        "\n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "\n",
        "  print(f\"正在執行{n_splits}-Fold Cross-Validation以評估穩定性\")\n",
        "\n",
        "  # 使用StratifiedKFold確保每一折的類別比例一致\n",
        "  cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "  # 計算分數\n",
        "  scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
        "  print(\"-\" * 40)\n",
        "  print(f\"各折分數(Scores per fold):{np.round(scores,4)}\")\n",
        "  print(f\"平均準確率 (Mean Accuracy): {scores.mean():.4f}\")\n",
        "  print(f\"標準差 (Standard Deviation): {scores.std():.4f}\")\n",
        "  print(\"-\" * 40)\n",
        "\n",
        "  # 判斷穩定性\n",
        "  if scores.std() < 0.05:\n",
        "    print(\"模型穩定性良好: 標準差<0.05\")\n",
        "  else:\n",
        "    print(\"模型波動較大，建議調整數據量或參數\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdvLmU9RhSZD"
      },
      "source": [
        "✈"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tgZyQGt8hT8-",
        "outputId": "025849ff-6782-499c-a381-c8005eda5645"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RF model 穩定性：\n",
            "\n",
            "正在執行5-Fold Cross-Validation以評估穩定性\n",
            "----------------------------------------\n",
            "各折分數(Scores per fold):[0.8571 0.8783 0.8598 0.8647 0.8488]\n",
            "平均準確率 (Mean Accuracy): 0.8618\n",
            "標準差 (Standard Deviation): 0.0098\n",
            "----------------------------------------\n",
            "模型穩定性良好: 標準差<0.05\n",
            "\n",
            "XGB model 穩定性：\n",
            "正在執行5-Fold Cross-Validation以評估穩定性\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [02:54:36] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [02:54:37] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [02:54:38] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [02:54:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [02:54:40] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "各折分數(Scores per fold):[0.873  0.8757 0.873  0.8568 0.8594]\n",
            "平均準確率 (Mean Accuracy): 0.8676\n",
            "標準差 (Standard Deviation): 0.0078\n",
            "----------------------------------------\n",
            "模型穩定性良好: 標準差<0.05\n"
          ]
        }
      ],
      "source": [
        "print(\"RF model 穩定性：\\n\")\n",
        "check_model_stability(rf_model, X_train, y_train)\n",
        "print(\"\\nXGB model 穩定性：\")\n",
        "check_model_stability(xgb_model, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hULai1A4n0eQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import torch\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "# 1. 設定參數與準備\n",
        "k_folds = 5\n",
        "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "results = [] # 用於記錄每一 fold 的結果\n",
        "\n",
        "print(f\"開始 {k_folds}-Fold 交叉驗證\")\n",
        "\n",
        "# 2. 開始切分資料\n",
        "# dataset 是你原始的 PyG Dataset 物件\n",
        "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
        "    print(f\"\\n--- Fold {fold + 1} ---\")\n",
        "\n",
        "    # 根據索引建立該 Fold 的 Subset\n",
        "    train_sub = [dataset[i] for i in train_ids]\n",
        "    test_sub = [dataset[i] for i in test_ids]\n",
        "\n",
        "    # 建立該 Fold 專用的 DataLoader\n",
        "    train_loader = DataLoader(train_sub, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_sub, batch_size=32, shuffle=False)\n",
        "\n",
        "    # 每個 Fold 都要「重新初始化」模型與優化器，確保不互相污染\n",
        "    model = GCN(num_node_features=7).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # 3. 訓練循環 (簡化為 20 epochs 作示範)\n",
        "    for epoch in range(1, 21):\n",
        "        # 這裡調用你之前寫好的 train() 函數\n",
        "        # 注意：train() 內部的 loader 需改為當前的 train_loader\n",
        "        loss = train_with_loader(model, train_loader, optimizer, criterion)\n",
        "\n",
        "    # 4. 評估模型\n",
        "    # 調用你之前的 test() 函數取得該 fold 的表現\n",
        "    auc, f1 = test_with_loader(model, test_loader)\n",
        "    print(f\"Fold {fold + 1} 結果: AUC: {auc:.4f}, F1: {f1:.4f}\")\n",
        "\n",
        "    results.append((auc, f1))\n",
        "\n",
        "# 5. 計算平均表現\n",
        "avg_auc = sum(r[0] for r in results) / k_folds\n",
        "avg_f1 = sum(r[1] for r in results) / k_folds\n",
        "print(f\"\\n最終平均表現: AUC: {avg_auc:.4f}, F1: {avg_f1:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}